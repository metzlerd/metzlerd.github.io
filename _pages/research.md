---
layout: archive
title: "Research"
permalink: /research/
author_profile: true
redirect_from:
  - /research
---

My current research areas include language modeling foundations, safety, factuality, and retrieval/ranking. The work
from my teams and I has contributed to some of Google's most significant product launches, including Gemini and Search.

To get a technical sense of my research, see my [Scholar profile](https://scholar.google.com/citations?user=bmXpOd8AAAAJ&hl=en) or my [CV](../files/metzler-cv.pdf). 
Below are some selected recent publications and links to articles and videos that provide a broader perspective on the impact of the research.

## Selected Recent Publications
* Gemini Team. "[Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities](https://arxiv.org/abs/2507.06261)," *arXiv*, 2025.
* Balog, K., Metzler, D., and Qin, Z. "[Rankers, Judges, and Assistants: Towards Understanding the Interplay of LLMs in Information Retrieval Evaluation](https://arxiv.org/abs/2503.19092)," in *SIGIR*, 2025.
* Baumgärtner, T., Gao, Y., Alon, D., and Metzler, D. "[Best-of-Venom: Attacking RLHF by Injecting Poisoned Preference Data](https://arxiv.org/abs/2404.05530)," in *COLM*, 2024.
* Gao, Y., Alon, D., and Metzler, D. "[Impact of Preference Noise on the Alignment Performance of Generative Language Models](https://arxiv.org/abs/2404.09824)," in *COLM*, 2024.
* Qin, Z., Jagerman, R., Hui, K., et al. "[Large Language Models are Effective Text Rankers with Pairwise Ranking Prompting](https://arxiv.org/abs/2306.17563)," in *Findings of NAACL*, 2023.
* Pradeep, R., Hui, K., Gupta, J., et al. "[How Does Generative Retrieval Scale to Millions of Passages?](https://arxiv.org/abs/2305.11841)," in *EMNLP*, 2023.

## Articles
* **July 2025:** Gemini 2.5: Our most intelligent AI model ([The Keyword](https://blog.google/technology/google-deepmind/gemini-model-thinking-updates-march-2025/))
* **March 2024:** New ways we’re tackling spammy, low-quality content on Search ([The Keyword](https://blog.google/products/search/google-search-update-march-2024/))
* **March 2024:** Google is starting to squash more spam and AI in search results ([The Verge](https://www.theverge.com/2024/3/5/24091099/google-search-high-quality-results-spam-ai-content))
* **September 2023:** Improving Trust in AI and Online Communities with PaLM-based Moderation ([Google Cloud Blog](https://cloud.google.com/blog/products/ai-machine-learning/google-cloud-text-moderation))
* **July 2023:** Google’s Jigsaw was trying to fight toxic speech with AI. Then the AI started talking ([Fast Company](https://www.fastcompany.com/90929549/google-jigsaw-toxic-speech-ai))
* **June 2021:** Google Hopes AI Can Turn Search Into a Conversation ([Wired](https://www.wired.com/story/google-hopes-ai-turn-search-conversation/))
* **May 2021:** Google isn’t ready to turn search into a conversation ([The Verge](https://www.theverge.com/2021/5/26/22454513/google-future-of-search-conversation-ai-mum-lamda))
* **May 2021:** Language models like GPT-3 could herald a new type of search engine ([MIT Technology Review](https://www.technologyreview.com/2021/05/14/1024918/language-models-gpt3-search-engine-google/))

## Blog Posts
* **December 2022:** Accelerating text generation with Confident Adaptive Language Modeling (CALM) ([Google Research Blog](https://blog.research.google/2022/12/accelerating-text-generation-with.html))
* **October 2022:** UL2 20B: An Open Source Unified Language Learner ([Google Research Blog](https://blog.research.google/2022/10/ul2-20b-open-source-unified-language.html))

## YouTube Videos
* **April 2022:** Transformer Memory as a Differentiable Search Index (Machine Learning Research Paper Explained)
  ([Yannic Kilcher YouTube Video](https://www.youtube.com/watch?v=qlB0TPBQ7YY&ab_channel=YannicKilcher))
* **November 2021:** ExT5: Towards Extreme Multi-Task Scaling for Transfer Learning (Paper Explained) ([Yannic Kilcher YouTube Video](https://www.youtube.com/watch?v=FbRcbM4T-50&ab_channel=YannicKilcher))